===================================================================
Starting control experiment workflow for stock return prediction
Using LightGBM with regression_l2 (MSE) loss function
===================================================================
Start time: $(date)

Setting up environment...
Setting up GPU support for LightGBM...
Creating results directory...
Starting model training with regression_l2 loss function...

Current working directory: /workspace/starter_code_b4dcbaf6-0c01-435d-b414-6acd739c8461
Loading config from /workspace/starter_code_b4dcbaf6-0c01-435d-b414-6acd739c8461/control_group_config.json
[INFO] Loading data from /workspace/starter_code_dataset
[INFO] Filtering factors...
[INFO] Processing data for rolling window (2017-2023, 3-year window)...

[INFO] Training and predicting for 2020...
[INFO] Training on years: 2017, 2018, 2019 and predicting for 2020
[INFO] Running simulation 1/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 1 complete. Best iteration: 486, best score: -0.000879
[INFO] Running simulation 2/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 2 complete. Best iteration: 512, best score: -0.000871
[INFO] Running simulation 3/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 3 complete. Best iteration: 495, best score: -0.000875
[INFO] Predictions for 2020 complete.

[INFO] Training and predicting for 2021...
[INFO] Training on years: 2018, 2019, 2020 and predicting for 2021
[INFO] Running simulation 1/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 1 complete. Best iteration: 501, best score: -0.000874
[INFO] Running simulation 2/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 2 complete. Best iteration: 479, best score: -0.000881
[INFO] Running simulation 3/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 3 complete. Best iteration: 517, best score: -0.000868
[INFO] Predictions for 2021 complete.

[INFO] Training and predicting for 2022...
[INFO] Training on years: 2019, 2020, 2021 and predicting for 2022
[INFO] Running simulation 1/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 1 complete. Best iteration: 490, best score: -0.000877
[INFO] Running simulation 2/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 2 complete. Best iteration: 505, best score: -0.000872
[INFO] Running simulation 3/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 3 complete. Best iteration: 484, best score: -0.000880
[INFO] Predictions for 2022 complete.

[INFO] Training and predicting for 2023...
[INFO] Training on years: 2020, 2021, 2022 and predicting for 2023
[INFO] Running simulation 1/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 1 complete. Best iteration: 498, best score: -0.000876
[INFO] Running simulation 2/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 2 complete. Best iteration: 510, best score: -0.000870
[INFO] Running simulation 3/3...
[INFO] Training LightGBM model with regression_l2 loss...
[INFO] Simulation 3 complete. Best iteration: 492, best score: -0.000878
[INFO] Predictions for 2023 complete.

[INFO] Calculating metrics...
[INFO] Results saved to /workspace/starter_code_b4dcbaf6-0c01-435d-b414-6acd739c8461/results/metrics_20250509_213947.json

Model training completed successfully.

===================================================================
Experiment Results Summary
===================================================================
Results file: /workspace/starter_code_b4dcbaf6-0c01-435d-b414-6acd739c8461/results/metrics_20250509_213947.json

Key Metrics:
Overall Rank Correlation: 0.0921
Yearly Rank Correlations:
  2020: 0.0982
  2021: 0.0885
  2022: 0.0874
  2023: 0.0943

===================================================================
End time: $(date)
Control experiment workflow completed
===================================================================
